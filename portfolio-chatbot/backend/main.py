from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, Any, List
import json
import os
import logging
from datetime import datetime
import uuid
import re
import asyncio
from playwright.async_api import async_playwright
import aiohttp
from dataclasses import dataclass

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/app.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

app = FastAPI(title="AI Portfolio Agent", version="2.0.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë°ì´í„° ëª¨ë¸
class ChatRequest(BaseModel):
    message: str
    session_id: Optional[str] = None
    company: Optional[str] = None

class ChatResponse(BaseModel):
    response: str
    session_id: str
    detected_company: Optional[str] = None
    agent_actions: Optional[List[str]] = None

@dataclass
class CompanyInfo:
    name: str
    job_postings: List[Dict]
    company_culture: Dict
    tech_requirements: List[str]
    hiring_process: str

# Agent Tools
class WebScrapingAgent:
    def __init__(self):
        self.playwright = None
        self.browser = None
        
    async def initialize(self):
        """Playwright ë¸Œë¼ìš°ì € ì´ˆê¸°í™”"""
        try:
            self.playwright = await async_playwright().start()
            self.browser = await self.playwright.chromium.launch(headless=True)
            logger.info("Agent browser initialized")
        except Exception as e:
            logger.error(f"Failed to initialize browser: {e}")
    
    async def close(self):
        """ë¸Œë¼ìš°ì € ì¢…ë£Œ"""
        if self.browser:
            await self.browser.close()
        if self.playwright:
            await self.playwright.stop()
    
    async def search_job_postings(self, company_name: str) -> List[Dict]:
        """ì±„ìš© ì •ë³´ í¬ë¡¤ë§"""
        if not self.browser:
            await self.initialize()
            
        actions = []
        job_postings = []
        
        try:
            page = await self.browser.new_page()
            actions.append(f"ðŸ” {company_name} ì±„ìš©ì •ë³´ ê²€ìƒ‰ ì‹œìž‘")
            
            # ì‚¬ëžŒì¸ ê²€ìƒ‰
            search_url = f"https://www.saramin.co.kr/zf_user/search/recruit?searchType=search&searchword={company_name}"
            await page.goto(search_url, wait_until="domcontentloaded")
            actions.append("ðŸ“Š ì‚¬ëžŒì¸ ì±„ìš©ê³µê³  ë¶„ì„")
            
            await page.wait_for_timeout(2000)  # íŽ˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
            
            # ì±„ìš©ê³µê³  ì •ë³´ ì¶”ì¶œ
            job_elements = await page.query_selector_all('.item_recruit')
            
            for i, element in enumerate(job_elements[:3]):  # ìƒìœ„ 3ê°œë§Œ
                try:
                    title_elem = await element.query_selector('.job_tit a')
                    company_elem = await element.query_selector('.corp_name a')
                    condition_elem = await element.query_selector('.job_condition')
                    
                    if title_elem and company_elem:
                        title = await title_elem.inner_text()
                        company = await company_elem.inner_text()
                        condition = await condition_elem.inner_text() if condition_elem else ""
                        
                        if company_name.lower() in company.lower():
                            job_postings.append({
                                'title': title.strip(),
                                'company': company.strip(),
                                'condition': condition.strip(),
                                'source': 'ì‚¬ëžŒì¸'
                            })
                except Exception as e:
                    logger.warning(f"Failed to extract job posting {i}: {e}")
                    continue
            
            await page.close()
            actions.append(f"âœ… {len(job_postings)}ê°œ ì±„ìš©ê³µê³  ìˆ˜ì§‘ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"Job scraping failed: {e}")
            actions.append(f"âŒ ì±„ìš©ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            
        return job_postings, actions
    
    async def get_company_culture(self, company_name: str) -> Dict:
        """íšŒì‚¬ ë¬¸í™”/ì •ë³´ í¬ë¡¤ë§"""
        if not self.browser:
            await self.initialize()
            
        culture_info = {}
        actions = []
        
        try:
            page = await self.browser.new_page()
            actions.append(f"ðŸ¢ {company_name} ê¸°ì—…ì •ë³´ ìˆ˜ì§‘")
            
            # ìž¡í”Œëž˜ë‹›ì—ì„œ íšŒì‚¬ ì •ë³´ ê²€ìƒ‰
            search_url = f"https://www.jobplanet.co.kr/search?query={company_name}"
            await page.goto(search_url, wait_until="domcontentloaded")
            await page.wait_for_timeout(3000)
            
            # ê¸°ì—… ë¬¸í™” ì •ë³´ ì¶”ì¶œ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
            try:
                # ì²« ë²ˆì§¸ ê²€ìƒ‰ ê²°ê³¼ í´ë¦­
                first_company = await page.query_selector('.company_name a')
                if first_company:
                    await first_company.click()
                    await page.wait_for_timeout(2000)
                    
                    # ê¸°ì—… ê°œìš” ì •ë³´ ì¶”ì¶œ
                    overview_elem = await page.query_selector('.company_overview')
                    if overview_elem:
                        overview_text = await overview_elem.inner_text()
                        culture_info['overview'] = overview_text[:300]  # 300ìž ì œí•œ
                    
                    actions.append("âœ… ê¸°ì—… ë¬¸í™” ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
                else:
                    culture_info['overview'] = f"{company_name}ëŠ” í˜ì‹ ì ì¸ ê¸°ì—…ìœ¼ë¡œ ì•Œë ¤ì ¸ ìžˆìŠµë‹ˆë‹¤."
                    actions.append("âš ï¸ ê¸°ë³¸ ê¸°ì—…ì •ë³´ ì‚¬ìš©")
                    
            except Exception as e:
                culture_info['overview'] = f"{company_name}ì—ì„œ í•¨ê»˜ ì„±ìž¥í•  ê¸°íšŒë¥¼ ê¸°ëŒ€í•©ë‹ˆë‹¤."
                actions.append(f"âš ï¸ ê¸°ì—…ì •ë³´ ìˆ˜ì§‘ ì œí•œì : {str(e)}")
            
            await page.close()
            
        except Exception as e:
            logger.error(f"Company culture scraping failed: {e}")
            actions.append(f"âŒ ê¸°ì—…ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨")
            culture_info['overview'] = f"{company_name}ì™€ í•¨ê»˜ ì„±ìž¥í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤."
            
        return culture_info, actions

# ì „ì—­ Agent ì¸ìŠ¤í„´ìŠ¤
web_agent = WebScrapingAgent()

# ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ë“¤
def load_resume_data():
    with open('data/resume.json', 'r', encoding='utf-8') as f:
        return json.load(f)

def extract_company_name(message: str) -> Optional[str]:
    company_patterns = {
        'ë„¤ì´ë²„': ['ë„¤ì´ë²„', 'naver', 'NAVER', 'Naver'],
        'ì¹´ì¹´ì˜¤': ['ì¹´ì¹´ì˜¤', 'kakao', 'KAKAO', 'Kakao'],
        'ì¿ íŒ¡': ['ì¿ íŒ¡', 'coupang', 'COUPANG', 'Coupang'],
        'í† ìŠ¤': ['í† ìŠ¤', 'toss', 'TOSS', 'Toss'],
        'ì‚¼ì„±': ['ì‚¼ì„±', 'samsung', 'SAMSUNG', 'Samsung'],
        'LG': ['LG', 'lg', 'ì—˜ì§€'],
        'í˜„ëŒ€': ['í˜„ëŒ€', 'hyundai', 'HYUNDAI']
    }
    
    message_lower = message.lower()
    
    for company, patterns in company_patterns.items():
        for pattern in patterns:
            if pattern.lower() in message_lower:
                return company
    
    return None

async def generate_agent_response(message: str, company: str = None) -> tuple[str, List[str]]:
    """AI Agent ê¸°ë°˜ ì‘ë‹µ ìƒì„±"""
    resume_data = load_resume_data()
    all_actions = []
    
    if not company:
        company = extract_company_name(message)
    
    if company:
        all_actions.append(f"ðŸŽ¯ {company} ê´€ë ¨ ì§ˆë¬¸ ê°ì§€")
        
        # Agent ì‹¤í–‰: ì‹¤ì‹œê°„ ì •ë³´ ìˆ˜ì§‘
        job_postings, job_actions = await web_agent.search_job_postings(company)
        company_culture, culture_actions = await web_agent.get_company_culture(company)
        
        all_actions.extend(job_actions)
        all_actions.extend(culture_actions)
        
        # ë¶„ì„ ë° ê°œì¸í™” ë‹µë³€ ìƒì„±
        all_actions.append("ðŸ§  ê°œì¸ ì´ë ¥ê³¼ ê¸°ì—…ì •ë³´ ë§¤ì¹­ ë¶„ì„")
        
        # ê°„ë‹¨í•œ ë§¤ì¹­ ë¡œì§ (ë‚˜ì¤‘ì— XAI APIë¡œ ëŒ€ì²´)
        my_skills = [skill['name'] for skill in resume_data['skills']['backend']]
        
        if job_postings:
            relevant_jobs = [job for job in job_postings if any(skill.lower() in job['condition'].lower() for skill in my_skills)]
            
            if relevant_jobs:
                response = f"""ðŸŽ¯ {company} ë§žì¶¤ ë¶„ì„ ê²°ê³¼:

ðŸ“‹ **ìµœì‹  ì±„ìš©ì •ë³´** (ì‹¤ì‹œê°„ ìˆ˜ì§‘):
{relevant_jobs[0]['title']}
â€¢ ìš”êµ¬ì‚¬í•­: {relevant_jobs[0]['condition'][:100]}...

ðŸ¤ **ì €ì™€ì˜ ë§¤ì¹­ë„**:
â€¢ ì œê°€ ë³´ìœ í•œ {', '.join(my_skills[:3])} ê¸°ìˆ ì´ í•´ë‹¹ í¬ì§€ì…˜ê³¼ ì í•©í•©ë‹ˆë‹¤
â€¢ {resume_data['experience'][0]['achievements'][0]} ê²½í—˜ì´ ë„ì›€ì´ ë  ê²ƒ ê°™ìŠµë‹ˆë‹¤

ðŸ’¡ **ì§€ì› ì´ìœ **:
íŽ¸ì˜ì ê°™ì€ ê°œë°œìžë¡œì„œ {company}ì˜ ì‚¬ìš©ìžë“¤ì—ê²Œ 24/7 íŽ¸ë¦¬í•¨ì„ ì œê³µí•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. íŠ¹ížˆ {company_culture.get('overview', 'í˜ì‹ ì ì¸ ê¸°ì—…ë¬¸í™”')}ì™€ ì œ ê°€ì¹˜ê´€ì´ ì¼ì¹˜í•œë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤.

ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì´ ìžˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”! ðŸš€"""
            else:
                response = f"""ðŸŽ¯ {company}ì— ëŒ€í•œ ê´€ì‹¬ ê°ì‚¬í•©ë‹ˆë‹¤!

ì‹¤ì‹œê°„ìœ¼ë¡œ ì±„ìš©ì •ë³´ë¥¼ í™•ì¸í–ˆì§€ë§Œ, í˜„ìž¬ ê³µê°œëœ í¬ì§€ì…˜ê³¼ ì œ ê¸°ìˆ ìŠ¤íƒì˜ ì§ì ‘ì ì¸ ë§¤ì¹­ì€ ì œí•œì ìž…ë‹ˆë‹¤. 

í•˜ì§€ë§Œ íŽ¸ì˜ì ê°™ì€ ê°œë°œìžë¡œì„œ:
â€¢ **íŽ¸ë¦¬í•¨ ì¶”êµ¬**: ì‚¬ìš©ìž ì¤‘ì‹¬ì˜ ì„œë¹„ìŠ¤ ê°œë°œ 
â€¢ **ì˜ë¡œì›€ ì‹¤ì²œ**: ì˜¬ë°”ë¥¸ ê°€ì¹˜ê´€ìœ¼ë¡œ ê°œë°œ
â€¢ **ì§€ì† ì„±ìž¥**: ìƒˆë¡œìš´ ê¸°ìˆ  í•™ìŠµì— ì ê·¹ì 

{company}ì™€ í•¨ê»˜ ì„±ìž¥í•˜ë©° ê¸°ì—¬í•  ì¤€ë¹„ê°€ ë˜ì–´ ìžˆìŠµë‹ˆë‹¤! ðŸ’ª"""
        else:
            response = f"""ðŸŽ¯ {company}ì— ê´€ì‹¬ ê°€ì ¸ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!

í˜„ìž¬ ê³µê°œëœ ì±„ìš©ì •ë³´ ìˆ˜ì§‘ì— ì¼ì‹œì ì¸ ì œí•œì´ ìžˆì§€ë§Œ, íŽ¸ì˜ì ê°™ì€ ê°œë°œìžë¡œì„œ {company}ì— ê¸°ì—¬í•  ìˆ˜ ìžˆëŠ” ë°©ë²•ë“¤:

ðŸ›  **ê¸°ìˆ ì  ê¸°ì—¬**:
â€¢ {', '.join(my_skills[:3])} ë“±ì˜ ê¸°ìˆ ë¡œ ì•ˆì •ì ì¸ ì„œë¹„ìŠ¤ êµ¬ì¶•
â€¢ {resume_data['projects'][0]['description'][:50]}... ê²½í—˜ í™œìš©

ðŸ¤ **ê°€ì¹˜ ì—°ê²°**:
íŽ¸ì˜ì ì²˜ëŸ¼ í•­ìƒ ì¤€ë¹„ëœ ê°œë°œìžë¡œì„œ {company}ì˜ ì‚¬ìš©ìžë“¤ì—ê²Œ íŽ¸ë¦¬í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìžˆëŠ” ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤.

êµ¬ì²´ì ì¸ í¬ì§€ì…˜ì´ë‚˜ í”„ë¡œì íŠ¸ì— ëŒ€í•´ ë” ê¶ê¸ˆí•œ ì ì´ ìžˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”! ðŸš€"""
        
        all_actions.append("âœ… ë§žì¶¤í˜• ë‹µë³€ ìƒì„± ì™„ë£Œ")
        
    else:
        # ì¼ë°˜ì ì¸ ì§ˆë¬¸ ì²˜ë¦¬
        message_lower = message.lower()
        
        if 'ê²½ë ¥' in message_lower or 'experience' in message_lower:
            experience = resume_data['experience'][0]
            response = f"**ê²½ë ¥ ì†Œê°œ**:\n{experience['position']}ë¡œ {experience['duration']} ê·¼ë¬´í•˜ë©° {', '.join(experience['achievements'])} ë“±ì˜ ì„±ê³¼ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. íŽ¸ì˜ì ê°™ì€ ê°œë°œìžë¡œì„œ í•­ìƒ ì‚¬ìš©ìžì—ê²Œ íŽ¸ë¦¬í•¨ì„ ì œê³µí•˜ë ¤ ë…¸ë ¥í•©ë‹ˆë‹¤."
        
        elif 'í”„ë¡œì íŠ¸' in message_lower:
            project = resume_data['projects'][0]
            response = f"**í”„ë¡œì íŠ¸ ê²½í—˜**:\n{project['name']} - {project['description']} íŠ¹ížˆ {project['role']}ë¡œì„œ {project['challenges'][:100]}..."
            
        elif 'ê¸°ìˆ ' in message_lower or 'tech' in message_lower:
            skills = resume_data['skills']['backend']
            tech_list = [f"{skill['name']}({skill['level']})" for skill in skills[:3]]
            response = f"**ê¸°ìˆ  ìŠ¤íƒ**:\nì£¼ìš” ê¸°ìˆ ì€ {', '.join(tech_list)} ë“±ìž…ë‹ˆë‹¤. íŽ¸ì˜ì ê°™ì€ ê°œë°œìžë¡œì„œ ì‚¬ìš©ìžê°€ í•„ìš”í•  ë•Œ ì–¸ì œë“  ë„ì›€ì´ ë˜ëŠ” ê¸°ìˆ ì„ ë³´ìœ í•˜ê³  ìžˆìŠµë‹ˆë‹¤."
            
        else:
            response = f"""ì•ˆë…•í•˜ì„¸ìš”! íŽ¸ì˜ì ê°™ì€ ê°œë°œìž **ì‹ ì¤€í¬**ìž…ë‹ˆë‹¤! ðŸª

{resume_data['personal_info']['intro']}

ðŸ’¡ **ê¶ê¸ˆí•œ ì ì´ ìžˆìœ¼ì‹œë©´**:
â€¢ "ë„¤ì´ë²„ì— ì§€ì›í•˜ëŠ” ì´ìœ ëŠ”?" (ì‹¤ì‹œê°„ ê¸°ì—… ë¶„ì„)
â€¢ "í”„ë¡œì íŠ¸ ê²½í—˜ì„ ì•Œë ¤ì£¼ì„¸ìš”"
â€¢ "ì–´ë–¤ ê¸°ìˆ  ìŠ¤íƒì„ ì‚¬ìš©í•˜ë‚˜ìš”?"

ì–¸ì œë“  íŽ¸í•˜ê²Œ ë¬¼ì–´ë³´ì„¸ìš”! 24/7 ì¤€ë¹„ëœ ê°œë°œìžìž…ë‹ˆë‹¤ ðŸš€"""
        
        all_actions.append("ðŸ’¬ ì¼ë°˜ ì§ˆë¬¸ ì‘ë‹µ ì™„ë£Œ")
    
    return response, all_actions

# ë¡œê·¸ ì €ìž¥
def save_chat_log(session_id: str, message: str, response: str, company: str = None, agent_actions: List[str] = None):
    log_entry = {
        "timestamp": datetime.now().isoformat(),
        "session_id": session_id,
        "company": company,
        "user_message": message,
        "bot_response": response,
        "agent_actions": agent_actions or []
    }
    
    date_str = datetime.now().strftime("%Y%m%d")
    log_file = f"logs/chat_{date_str}.json"
    
    if os.path.exists(log_file):
        with open(log_file, 'r', encoding='utf-8') as f:
            logs = json.load(f)
    else:
        logs = []
    
    logs.append(log_entry)
    
    with open(log_file, 'w', encoding='utf-8') as f:
        json.dump(logs, f, ensure_ascii=False, indent=2)

@app.get("/")
async def root():
    return {"message": "AI Portfolio Agent v2.0", "status": "running"}

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    try:
        session_id = request.session_id or str(uuid.uuid4())
        detected_company = request.company or extract_company_name(request.message)
        
        # Agent ê¸°ë°˜ ì‘ë‹µ ìƒì„±
        response, agent_actions = await generate_agent_response(request.message, detected_company)
        
        # ë¡œê·¸ ì €ìž¥
        save_chat_log(
            session_id=session_id,
            message=request.message,
            response=response,
            company=detected_company,
            agent_actions=agent_actions
        )
        
        logger.info(f"Agent processed - Session: {session_id}, Company: {detected_company}, Actions: {len(agent_actions)}")
        
        return ChatResponse(
            response=response,
            session_id=session_id,
            detected_company=detected_company,
            agent_actions=agent_actions
        )
        
    except Exception as e:
        logger.error(f"Agent processing error: {str(e)}")
        raise HTTPException(status_code=500, detail="Agent processing failed")

@app.get("/admin/logs/{date}")
async def get_logs(date: str):
    try:
        log_file = f"logs/chat_{date}.json"
        if os.path.exists(log_file):
            with open(log_file, 'r', encoding='utf-8') as f:
                logs = json.load(f)
            return {"logs": logs}
        else:
            return {"logs": [], "message": "No logs found for this date"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/admin/analytics")
async def get_analytics():
    try:
        date_str = datetime.now().strftime("%Y%m%d")
        log_file = f"logs/chat_{date_str}.json"
        
        if not os.path.exists(log_file):
            return {"message": "No data for today"}
            
        with open(log_file, 'r', encoding='utf-8') as f:
            logs = json.load(f)
        
        total_chats = len(logs)
        companies = {}
        agent_usage = sum(1 for log in logs if log.get('agent_actions'))
        
        for log in logs:
            if log.get('company'):
                companies[log['company']] = companies.get(log['company'], 0) + 1
        
        return {
            "total_chats_today": total_chats,
            "agent_activations": agent_usage,
            "companies": companies,
            "most_active_company": max(companies.items(), key=lambda x: x[1])[0] if companies else None,
            "agent_usage_rate": f"{(agent_usage/total_chats*100):.1f}%" if total_chats > 0 else "0%"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.on_event("shutdown")
async def shutdown_event():
    await web_agent.close()

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
